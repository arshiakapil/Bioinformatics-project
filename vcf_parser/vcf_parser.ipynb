{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VCF File Parser\n",
    "\n",
    "A parser for Variant Call Format (VCF) files supporting both uncompressed (`.vcf`) and compressed (`.vcf.gz`) formats.\n",
    "\n",
    "**Features:**\n",
    "- Parses VCF v4.1/4.2/4.3 files\n",
    "- Handles both `.vcf` and `.vcf.gz` (bgzip/gzip) compressed files\n",
    "- Stores results in a pandas DataFrame (optimal for columnar variant data)\n",
    "- Preserves metadata and header information\n",
    "- Unit tested with generated sample data\n",
    "- Performance benchmarked with visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import unittest\n",
    "import tempfile\n",
    "import shutil\n",
    "from dataclasses import dataclass, field\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "plt.rcParams.update({\"figure.dpi\": 120, \"font.size\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. VCF Parser Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class VCFHeader:\n",
    "    \"\"\"Stores parsed VCF header information.\"\"\"\n",
    "    meta_lines: list = field(default_factory=list)      # raw ## lines\n",
    "    info_fields: dict = field(default_factory=dict)      # INFO definitions\n",
    "    format_fields: dict = field(default_factory=dict)    # FORMAT definitions\n",
    "    filter_fields: dict = field(default_factory=dict)    # FILTER definitions\n",
    "    contig_fields: dict = field(default_factory=dict)    # contig definitions\n",
    "    sample_ids: list = field(default_factory=list)       # sample column names\n",
    "    file_format: str = \"\"                                # VCF version string\n",
    "\n",
    "\n",
    "class VCFParser:\n",
    "    \"\"\"Parser for VCF files (uncompressed and gzip-compressed).\n",
    "\n",
    "    Results are stored in a pandas DataFrame – an optimal columnar\n",
    "    data structure for variant data that supports fast filtering,\n",
    "    grouping, and statistical operations.\n",
    "    \"\"\"\n",
    "\n",
    "    MANDATORY_COLS = [\"CHROM\", \"POS\", \"ID\", \"REF\", \"ALT\", \"QUAL\", \"FILTER\", \"INFO\"]\n",
    "\n",
    "    def __init__(self, filepath: str):\n",
    "        self.filepath = filepath\n",
    "        self.header = VCFHeader()\n",
    "        self.variants: pd.DataFrame = pd.DataFrame()\n",
    "        self._parse_time: float = 0.0\n",
    "\n",
    "    # ---- public API --------------------------------------------------------\n",
    "\n",
    "    def parse(self) -> pd.DataFrame:\n",
    "        \"\"\"Parse the VCF file and return a DataFrame of variant records.\"\"\"\n",
    "        start = time.perf_counter()\n",
    "        opener = self._get_opener()\n",
    "        header_lines = []\n",
    "        data_lines = []\n",
    "\n",
    "        with opener(self.filepath, \"rt\") as fh:\n",
    "            for line in fh:\n",
    "                line = line.rstrip(\"\\n\")\n",
    "                if line.startswith(\"##\"):\n",
    "                    header_lines.append(line)\n",
    "                elif line.startswith(\"#CHROM\"):\n",
    "                    header_lines.append(line)\n",
    "                    self._parse_column_header(line)\n",
    "                else:\n",
    "                    if line:  # skip blank lines\n",
    "                        data_lines.append(line)\n",
    "\n",
    "        self._parse_meta(header_lines)\n",
    "        self._build_dataframe(data_lines)\n",
    "        self._parse_time = time.perf_counter() - start\n",
    "        return self.variants\n",
    "\n",
    "    def summary(self) -> dict:\n",
    "        \"\"\"Return summary statistics about the parsed VCF.\"\"\"\n",
    "        if self.variants.empty:\n",
    "            return {}\n",
    "        df = self.variants\n",
    "        return {\n",
    "            \"total_variants\": len(df),\n",
    "            \"chromosomes\": sorted(df[\"CHROM\"].unique().tolist()),\n",
    "            \"num_chromosomes\": df[\"CHROM\"].nunique(),\n",
    "            \"variant_types\": self._classify_variants().value_counts().to_dict(),\n",
    "            \"filter_counts\": df[\"FILTER\"].value_counts().to_dict(),\n",
    "            \"mean_quality\": float(df[\"QUAL\"].mean()) if df[\"QUAL\"].dtype != object else None,\n",
    "            \"num_samples\": len(self.header.sample_ids),\n",
    "            \"parse_time_sec\": round(self._parse_time, 4),\n",
    "        }\n",
    "\n",
    "    # ---- private helpers ---------------------------------------------------\n",
    "\n",
    "    def _get_opener(self):\n",
    "        \"\"\"Return the appropriate file opener based on extension.\"\"\"\n",
    "        if self.filepath.endswith(\".gz\"):\n",
    "            return gzip.open\n",
    "        return open\n",
    "\n",
    "    def _parse_column_header(self, line: str):\n",
    "        \"\"\"Parse the #CHROM header line to extract sample IDs.\"\"\"\n",
    "        cols = line.lstrip(\"#\").split(\"\\t\")\n",
    "        if len(cols) > 9:  # FORMAT + sample columns present\n",
    "            self.header.sample_ids = cols[9:]\n",
    "\n",
    "    def _parse_meta(self, header_lines: list):\n",
    "        \"\"\"Parse ## meta-information lines.\"\"\"\n",
    "        for line in header_lines:\n",
    "            if not line.startswith(\"##\"):\n",
    "                continue\n",
    "            self.header.meta_lines.append(line)\n",
    "            key_value = line[2:]  # strip leading ##\n",
    "\n",
    "            if key_value.startswith(\"fileformat=\"):\n",
    "                self.header.file_format = key_value.split(\"=\", 1)[1]\n",
    "            elif key_value.startswith(\"INFO=\"):\n",
    "                parsed = self._parse_structured_field(key_value[5:])\n",
    "                if parsed and \"ID\" in parsed:\n",
    "                    self.header.info_fields[parsed[\"ID\"]] = parsed\n",
    "            elif key_value.startswith(\"FORMAT=\"):\n",
    "                parsed = self._parse_structured_field(key_value[7:])\n",
    "                if parsed and \"ID\" in parsed:\n",
    "                    self.header.format_fields[parsed[\"ID\"]] = parsed\n",
    "            elif key_value.startswith(\"FILTER=\"):\n",
    "                parsed = self._parse_structured_field(key_value[7:])\n",
    "                if parsed and \"ID\" in parsed:\n",
    "                    self.header.filter_fields[parsed[\"ID\"]] = parsed\n",
    "            elif key_value.startswith(\"contig=\"):\n",
    "                parsed = self._parse_structured_field(key_value[7:])\n",
    "                if parsed and \"ID\" in parsed:\n",
    "                    self.header.contig_fields[parsed[\"ID\"]] = parsed\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_structured_field(raw: str) -> dict:\n",
    "        \"\"\"Parse a <key=value,...> structured header field.\"\"\"\n",
    "        raw = raw.strip()\n",
    "        if raw.startswith(\"<\") and raw.endswith(\">\"):\n",
    "            raw = raw[1:-1]\n",
    "        result = {}\n",
    "        # Handle Description which may contain commas inside quotes\n",
    "        parts = []\n",
    "        buf = []\n",
    "        in_quotes = False\n",
    "        for ch in raw:\n",
    "            if ch == '\"':\n",
    "                in_quotes = not in_quotes\n",
    "                buf.append(ch)\n",
    "            elif ch == ',' and not in_quotes:\n",
    "                parts.append(''.join(buf))\n",
    "                buf = []\n",
    "            else:\n",
    "                buf.append(ch)\n",
    "        if buf:\n",
    "            parts.append(''.join(buf))\n",
    "\n",
    "        for part in parts:\n",
    "            if '=' in part:\n",
    "                k, v = part.split('=', 1)\n",
    "                result[k.strip()] = v.strip().strip('\"')\n",
    "        return result\n",
    "\n",
    "    def _build_dataframe(self, data_lines: list):\n",
    "        \"\"\"Convert raw data lines into a typed pandas DataFrame.\"\"\"\n",
    "        if not data_lines:\n",
    "            self.variants = pd.DataFrame(columns=self.MANDATORY_COLS)\n",
    "            return\n",
    "\n",
    "        all_cols = self.MANDATORY_COLS.copy()\n",
    "        has_format = len(self.header.sample_ids) > 0\n",
    "        if has_format:\n",
    "            all_cols.append(\"FORMAT\")\n",
    "            all_cols.extend(self.header.sample_ids)\n",
    "\n",
    "        rows = [line.split(\"\\t\") for line in data_lines]\n",
    "        df = pd.DataFrame(rows)\n",
    "        # Assign column names for however many columns we actually got\n",
    "        df.columns = all_cols[: len(df.columns)]\n",
    "\n",
    "        # Type conversions\n",
    "        df[\"POS\"] = pd.to_numeric(df[\"POS\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        df[\"QUAL\"] = pd.to_numeric(df[\"QUAL\"].replace(\".\", np.nan), errors=\"coerce\")\n",
    "        df[\"CHROM\"] = df[\"CHROM\"].astype(\"category\")\n",
    "        df[\"FILTER\"] = df[\"FILTER\"].astype(\"category\")\n",
    "\n",
    "        self.variants = df\n",
    "\n",
    "    def _classify_variants(self) -> pd.Series:\n",
    "        \"\"\"Classify each variant as SNP, INS, DEL, or MNV.\"\"\"\n",
    "        def classify(row):\n",
    "            ref, alt = row[\"REF\"], str(row[\"ALT\"]).split(\",\")[0]\n",
    "            if len(ref) == 1 and len(alt) == 1:\n",
    "                return \"SNP\"\n",
    "            elif len(ref) > len(alt):\n",
    "                return \"DEL\"\n",
    "            elif len(ref) < len(alt):\n",
    "                return \"INS\"\n",
    "            else:\n",
    "                return \"MNV\"\n",
    "        return self.variants.apply(classify, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sample VCF File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_vcf(filepath: str, num_variants: int = 200,\n",
    "                        num_samples: int = 3, compressed: bool = False,\n",
    "                        seed: int = 42):\n",
    "    \"\"\"Generate a synthetic VCF file for testing.\"\"\"\n",
    "    rng = random.Random(seed)\n",
    "    bases = \"ACGT\"\n",
    "    chroms = [f\"chr{i}\" for i in range(1, 23)] + [\"chrX\", \"chrY\"]\n",
    "    sample_names = [f\"SAMPLE_{i+1}\" for i in range(num_samples)]\n",
    "    filters = [\"PASS\", \"PASS\", \"PASS\", \"PASS\", \"LowQual\", \"LowDP\"]\n",
    "\n",
    "    lines = []\n",
    "    # -- meta-information\n",
    "    lines.append(\"##fileformat=VCFv4.2\")\n",
    "    lines.append('##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Total read depth\">')\n",
    "    lines.append('##INFO=<ID=AF,Number=A,Type=Float,Description=\"Allele frequency\">')\n",
    "    lines.append('##INFO=<ID=MQ,Number=1,Type=Float,Description=\"Mapping quality\">')\n",
    "    lines.append('##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">')\n",
    "    lines.append('##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Sample read depth\">')\n",
    "    lines.append('##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\"Genotype quality\">')\n",
    "    lines.append('##FILTER=<ID=LowQual,Description=\"Low quality variant\">')\n",
    "    lines.append('##FILTER=<ID=LowDP,Description=\"Low depth variant\">')\n",
    "    for c in chroms:\n",
    "        lines.append(f'##contig=<ID={c},length={rng.randint(50_000_000, 250_000_000)}>')\n",
    "\n",
    "    # -- column header\n",
    "    cols = [\"#CHROM\", \"POS\", \"ID\", \"REF\", \"ALT\", \"QUAL\", \"FILTER\", \"INFO\", \"FORMAT\"]\n",
    "    cols.extend(sample_names)\n",
    "    lines.append(\"\\t\".join(cols))\n",
    "\n",
    "    # -- variant records\n",
    "    genotypes = [\"0/0\", \"0/1\", \"1/1\", \"0/0\", \"0/1\"]\n",
    "    for i in range(num_variants):\n",
    "        chrom = rng.choice(chroms)\n",
    "        pos = rng.randint(1, 200_000_000)\n",
    "        vid = f\"rs{rng.randint(100000, 9999999)}\" if rng.random() > 0.3 else \".\"\n",
    "        ref = rng.choice(bases)\n",
    "\n",
    "        # create different variant types\n",
    "        vtype = rng.random()\n",
    "        if vtype < 0.65:  # SNP\n",
    "            alt = rng.choice([b for b in bases if b != ref])\n",
    "        elif vtype < 0.80:  # insertion\n",
    "            alt = ref + ''.join(rng.choice(bases) for _ in range(rng.randint(1, 5)))\n",
    "        elif vtype < 0.95:  # deletion\n",
    "            ref = ref + ''.join(rng.choice(bases) for _ in range(rng.randint(1, 5)))\n",
    "            alt = ref[0]\n",
    "        else:  # multi-allelic SNP\n",
    "            alts = rng.sample([b for b in bases if b != ref], 2)\n",
    "            alt = \",\".join(alts)\n",
    "\n",
    "        qual = round(rng.uniform(5, 10000), 1)\n",
    "        filt = rng.choice(filters)\n",
    "        dp = rng.randint(5, 500)\n",
    "        af = round(rng.uniform(0.01, 1.0), 4)\n",
    "        mq = round(rng.uniform(20, 60), 1)\n",
    "        info = f\"DP={dp};AF={af};MQ={mq}\"\n",
    "        fmt = \"GT:DP:GQ\"\n",
    "\n",
    "        sample_data = []\n",
    "        for _ in sample_names:\n",
    "            gt = rng.choice(genotypes)\n",
    "            sdp = rng.randint(1, 200)\n",
    "            gq = rng.randint(1, 99)\n",
    "            sample_data.append(f\"{gt}:{sdp}:{gq}\")\n",
    "\n",
    "        fields = [chrom, str(pos), vid, ref, alt, str(qual), filt, info, fmt]\n",
    "        fields.extend(sample_data)\n",
    "        lines.append(\"\\t\".join(fields))\n",
    "\n",
    "    content = \"\\n\".join(lines) + \"\\n\"\n",
    "\n",
    "    if compressed:\n",
    "        with gzip.open(filepath, \"wt\") as f:\n",
    "            f.write(content)\n",
    "    else:\n",
    "        with open(filepath, \"w\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample files\n",
    "os.makedirs(\"test_data\", exist_ok=True)\n",
    "\n",
    "sample_vcf = generate_sample_vcf(\"test_data/sample.vcf\", num_variants=200)\n",
    "sample_vcf_gz = generate_sample_vcf(\"test_data/sample.vcf.gz\", num_variants=200, compressed=True)\n",
    "large_vcf = generate_sample_vcf(\"test_data/large.vcf\", num_variants=5000, seed=99)\n",
    "empty_vcf = generate_sample_vcf(\"test_data/empty.vcf\", num_variants=0)\n",
    "single_vcf = generate_sample_vcf(\"test_data/single.vcf\", num_variants=1)\n",
    "\n",
    "print(\"Generated test files:\")\n",
    "for f in sorted(os.listdir(\"test_data\")):\n",
    "    size = os.path.getsize(os.path.join(\"test_data\", f))\n",
    "    print(f\"  {f:25s}  {size:>8,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick Parse Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = VCFParser(\"test_data/sample.vcf\")\n",
    "df = parser.parse()\n",
    "\n",
    "print(\"Parsed VCF summary:\")\n",
    "for k, v in parser.summary().items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(\"\\nFirst 5 variants:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also parse compressed file\n",
    "parser_gz = VCFParser(\"test_data/sample.vcf.gz\")\n",
    "df_gz = parser_gz.parse()\n",
    "\n",
    "print(f\"Compressed parse: {len(df_gz)} variants in {parser_gz._parse_time:.4f}s\")\n",
    "print(f\"VCF version: {parser_gz.header.file_format}\")\n",
    "print(f\"Samples: {parser_gz.header.sample_ids}\")\n",
    "print(f\"INFO fields defined: {list(parser_gz.header.info_fields.keys())}\")\n",
    "print(f\"FILTER fields defined: {list(parser_gz.header.filter_fields.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class TestVCFParser(unittest.TestCase):\n    \"\"\"Unit tests for VCFParser.\"\"\"\n\n    @classmethod\n    def setUpClass(cls):\n        cls.tmpdir = tempfile.mkdtemp()\n        cls.vcf_path = os.path.join(cls.tmpdir, \"test.vcf\")\n        cls.vcf_gz_path = os.path.join(cls.tmpdir, \"test.vcf.gz\")\n        cls.empty_path = os.path.join(cls.tmpdir, \"empty.vcf\")\n        generate_sample_vcf(cls.vcf_path, num_variants=100, seed=1)\n        generate_sample_vcf(cls.vcf_gz_path, num_variants=100, seed=1, compressed=True)\n        generate_sample_vcf(cls.empty_path, num_variants=0, seed=1)\n\n    @classmethod\n    def tearDownClass(cls):\n        shutil.rmtree(cls.tmpdir)\n\n    # -- Basic parsing tests -------------------------------------------------\n\n    def test_parse_returns_dataframe(self):\n        parser = VCFParser(self.vcf_path)\n        result = parser.parse()\n        self.assertIsInstance(result, pd.DataFrame)\n\n    def test_correct_variant_count(self):\n        parser = VCFParser(self.vcf_path)\n        parser.parse()\n        self.assertEqual(len(parser.variants), 100)\n\n    def test_mandatory_columns_present(self):\n        parser = VCFParser(self.vcf_path)\n        parser.parse()\n        for col in VCFParser.MANDATORY_COLS:\n            self.assertIn(col, parser.variants.columns)\n\n    def test_pos_is_numeric(self):\n        parser = VCFParser(self.vcf_path)\n        parser.parse()\n        self.assertTrue(pd.api.types.is_integer_dtype(parser.variants[\"POS\"]))\n\n    def test_qual_is_numeric(self):\n        parser = VCFParser(self.vcf_path)\n        parser.parse()\n        self.assertTrue(pd.api.types.is_float_dtype(parser.variants[\"QUAL\"]))\n\n    # -- Compressed file tests -----------------------------------------------\n\n    def test_compressed_parse(self):\n        parser = VCFParser(self.vcf_gz_path)\n        parser.parse()\n        self.assertEqual(len(parser.variants), 100)\n\n    def test_compressed_matches_uncompressed(self):\n        p1 = VCFParser(self.vcf_path)\n        p1.parse()\n        p2 = VCFParser(self.vcf_gz_path)\n        p2.parse()\n        pd.testing.assert_frame_equal(p1.variants, p2.variants)\n\n    # -- Header tests --------------------------------------------------------\n\n    def test_file_format_parsed(self):\n        parser = VCFParser(self.vcf_path)\n        parser.parse()\n        self.assertEqual(parser.header.file_format, \"VCFv4.2\")\n\n    def test_info_fields_parsed(self):\n        parser = VCFParser(self.vcf_path)\n        parser.parse()\n        self.assertIn(\"DP\", parser.header.info_fields)\n        self.assertIn(\"AF\", parser.header.info_fields)\n\n    def test_sample_ids_parsed(self):\n        parser = VCFParser(self.vcf_path)\n        parser.parse()\n        self.assertEqual(len(parser.header.sample_ids), 3)\n        self.assertEqual(parser.header.sample_ids[0], \"SAMPLE_1\")\n\n    def test_filter_fields_parsed(self):\n        parser = VCFParser(self.vcf_path)\n        parser.parse()\n        self.assertIn(\"LowQual\", parser.header.filter_fields)\n\n    def test_contig_fields_parsed(self):\n        parser = VCFParser(self.vcf_path)\n        parser.parse()\n        self.assertGreater(len(parser.header.contig_fields), 0)\n\n    # -- Edge case tests -----------------------------------------------------\n\n    def test_empty_vcf(self):\n        parser = VCFParser(self.empty_path)\n        parser.parse()\n        self.assertEqual(len(parser.variants), 0)\n        self.assertIn(\"CHROM\", parser.variants.columns)\n\n    def test_summary_keys(self):\n        parser = VCFParser(self.vcf_path)\n        parser.parse()\n        s = parser.summary()\n        expected_keys = [\"total_variants\", \"chromosomes\", \"num_chromosomes\",\n                         \"variant_types\", \"filter_counts\", \"mean_quality\",\n                         \"num_samples\", \"parse_time_sec\"]\n        for key in expected_keys:\n            self.assertIn(key, s)\n\n    def test_summary_empty_vcf(self):\n        parser = VCFParser(self.empty_path)\n        parser.parse()\n        self.assertEqual(parser.summary(), {})\n\n    def test_chrom_is_categorical(self):\n        parser = VCFParser(self.vcf_path)\n        parser.parse()\n        self.assertIsInstance(parser.variants[\"CHROM\"].dtype, pd.CategoricalDtype)\n\n    def test_parse_time_recorded(self):\n        parser = VCFParser(self.vcf_path)\n        parser.parse()\n        self.assertGreater(parser._parse_time, 0)\n\n\n# Run tests inside the notebook\nsuite = unittest.TestLoader().loadTestsFromTestCase(TestVCFParser)\nrunner = unittest.TextTestRunner(verbosity=2)\nresult = runner.run(suite)\n\nprint(f\"\\n{'='*60}\")\nprint(f\"Tests run: {result.testsRun}\")\nprint(f\"Failures: {len(result.failures)}\")\nprint(f\"Errors: {len(result.errors)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 — Performance Benchmark: Parse Time vs File Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark parsing across different file sizes\n",
    "benchmark_sizes = [50, 200, 500, 1000, 2000, 5000]\n",
    "bench_dir = tempfile.mkdtemp()\n",
    "results = {\"format\": [], \"num_variants\": [], \"parse_time\": [], \"file_size_kb\": []}\n",
    "\n",
    "for n in benchmark_sizes:\n",
    "    for fmt, ext, comp in [(\"Uncompressed\", \".vcf\", False), (\"Compressed\", \".vcf.gz\", True)]:\n",
    "        path = os.path.join(bench_dir, f\"bench_{n}{ext}\")\n",
    "        generate_sample_vcf(path, num_variants=n, compressed=comp, seed=42)\n",
    "        fsize = os.path.getsize(path) / 1024\n",
    "\n",
    "        times = []\n",
    "        for _ in range(3):  # 3 runs for stable timing\n",
    "            p = VCFParser(path)\n",
    "            p.parse()\n",
    "            times.append(p._parse_time)\n",
    "\n",
    "        results[\"format\"].append(fmt)\n",
    "        results[\"num_variants\"].append(n)\n",
    "        results[\"parse_time\"].append(np.median(times))\n",
    "        results[\"file_size_kb\"].append(fsize)\n",
    "\n",
    "shutil.rmtree(bench_dir)\n",
    "bench_df = pd.DataFrame(results)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "for fmt, grp in bench_df.groupby(\"format\"):\n",
    "    ax.plot(grp[\"num_variants\"], grp[\"parse_time\"] * 1000,\n",
    "            marker=\"o\", linewidth=2, label=fmt)\n",
    "ax.set_xlabel(\"Number of Variants\")\n",
    "ax.set_ylabel(\"Parse Time (ms)\")\n",
    "ax.set_title(\"VCF Parse Time vs Number of Variants\")\n",
    "ax.legend()\n",
    "ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f\"{int(x):,}\"))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_data/benchmark_parse_time.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 — Compression Ratio: Uncompressed vs Compressed File Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "width = 0.35\n",
    "uncomp = bench_df[bench_df[\"format\"] == \"Uncompressed\"]\n",
    "comp = bench_df[bench_df[\"format\"] == \"Compressed\"]\n",
    "x = np.arange(len(benchmark_sizes))\n",
    "\n",
    "bars1 = ax.bar(x - width/2, uncomp[\"file_size_kb\"].values, width, label=\"Uncompressed\", color=\"#4C72B0\")\n",
    "bars2 = ax.bar(x + width/2, comp[\"file_size_kb\"].values, width, label=\"Compressed\", color=\"#55A868\")\n",
    "\n",
    "# Add compression ratio labels\n",
    "for i, (u, c) in enumerate(zip(uncomp[\"file_size_kb\"].values, comp[\"file_size_kb\"].values)):\n",
    "    ratio = u / c if c > 0 else 0\n",
    "    ax.annotate(f\"{ratio:.1f}x\", xy=(i + width/2, c), xytext=(0, 5),\n",
    "                textcoords=\"offset points\", ha=\"center\", fontsize=8, color=\"#55A868\")\n",
    "\n",
    "ax.set_xlabel(\"Number of Variants\")\n",
    "ax.set_ylabel(\"File Size (KB)\")\n",
    "ax.set_title(\"File Size: Uncompressed vs Compressed VCF\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f\"{s:,}\" for s in benchmark_sizes])\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_data/compression_ratio.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 — Variant Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser_lg = VCFParser(\"test_data/large.vcf\")\n",
    "df_lg = parser_lg.parse()\n",
    "vtype_counts = parser_lg._classify_variants().value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "colors = [\"#4C72B0\", \"#DD8452\", \"#55A868\", \"#C44E52\"]\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    vtype_counts.values, labels=vtype_counts.index,\n",
    "    autopct=\"%1.1f%%\", colors=colors[:len(vtype_counts)],\n",
    "    startangle=140, pctdistance=0.8\n",
    ")\n",
    "for t in autotexts:\n",
    "    t.set_fontsize(9)\n",
    "ax.set_title(f\"Variant Type Distribution (n={len(df_lg):,})\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_data/variant_types.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 — Chromosome Coverage: Variants per Chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_order = [f\"chr{i}\" for i in range(1, 23)] + [\"chrX\", \"chrY\"]\n",
    "chrom_counts = df_lg[\"CHROM\"].value_counts().reindex(chrom_order, fill_value=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bar_colors = [\"#4C72B0\" if c not in (\"chrX\", \"chrY\") else \"#C44E52\" for c in chrom_counts.index]\n",
    "ax.bar(range(len(chrom_counts)), chrom_counts.values, color=bar_colors)\n",
    "ax.set_xticks(range(len(chrom_counts)))\n",
    "ax.set_xticklabels(chrom_counts.index, rotation=45, ha=\"right\", fontsize=8)\n",
    "ax.set_xlabel(\"Chromosome\")\n",
    "ax.set_ylabel(\"Number of Variants\")\n",
    "ax.set_title(\"Chromosome Coverage — Variants per Chromosome\")\n",
    "\n",
    "mean_val = chrom_counts.mean()\n",
    "ax.axhline(y=mean_val, color=\"gray\", linestyle=\"--\", linewidth=1, label=f\"Mean = {mean_val:.0f}\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_data/chromosome_coverage.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 — Quality Score Distribution & FILTER Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Left: quality score histogram\n",
    "ax1 = axes[0]\n",
    "qual_vals = df_lg[\"QUAL\"].dropna()\n",
    "ax1.hist(qual_vals, bins=50, color=\"#4C72B0\", edgecolor=\"white\", linewidth=0.5)\n",
    "ax1.axvline(qual_vals.median(), color=\"#DD8452\", linestyle=\"--\", linewidth=2,\n",
    "            label=f\"Median = {qual_vals.median():.0f}\")\n",
    "ax1.set_xlabel(\"QUAL Score\")\n",
    "ax1.set_ylabel(\"Count\")\n",
    "ax1.set_title(\"Quality Score Distribution\")\n",
    "ax1.legend()\n",
    "\n",
    "# Right: filter status counts\n",
    "ax2 = axes[1]\n",
    "filter_counts = df_lg[\"FILTER\"].value_counts()\n",
    "colors_filter = [\"#55A868\" if f == \"PASS\" else \"#C44E52\" for f in filter_counts.index]\n",
    "ax2.barh(filter_counts.index.astype(str), filter_counts.values, color=colors_filter)\n",
    "ax2.set_xlabel(\"Count\")\n",
    "ax2.set_title(\"FILTER Status Counts\")\n",
    "\n",
    "# Add percentage labels\n",
    "total = filter_counts.sum()\n",
    "for i, (val, name) in enumerate(zip(filter_counts.values, filter_counts.index)):\n",
    "    ax2.text(val + total * 0.01, i, f\"{val/total*100:.1f}%\", va=\"center\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_data/quality_and_filters.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Coverage Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize what the test suite covers\n",
    "coverage_areas = {\n",
    "    \"Uncompressed parsing\":   True,\n",
    "    \"Compressed (.gz) parsing\": True,\n",
    "    \"Compressed == Uncompressed output\": True,\n",
    "    \"Column types (POS, QUAL)\": True,\n",
    "    \"Categorical CHROM/FILTER\": True,\n",
    "    \"Header: file format\":    True,\n",
    "    \"Header: INFO fields\":    True,\n",
    "    \"Header: FILTER fields\":  True,\n",
    "    \"Header: contig fields\":  True,\n",
    "    \"Header: sample IDs\":     True,\n",
    "    \"Empty VCF file\":         True,\n",
    "    \"Summary statistics\":     True,\n",
    "    \"Parse time tracking\":    True,\n",
    "}\n",
    "\n",
    "total = len(coverage_areas)\n",
    "covered = sum(coverage_areas.values())\n",
    "print(f\"Test coverage areas: {covered}/{total} ({covered/total*100:.0f}%)\")\n",
    "print()\n",
    "for area, status in coverage_areas.items():\n",
    "    mark = \"PASS\" if status else \"MISS\"\n",
    "    print(f\"  [{mark}] {area}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}